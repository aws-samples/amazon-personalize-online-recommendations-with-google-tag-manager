{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c137a45",
   "metadata": {},
   "source": [
    "Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "SPDX-License-Identifier: MIT-0\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this\n",
    "software and associated documentation files (the \"Software\"), to deal in the Software\n",
    "without restriction, including without limitation the rights to use, copy, modify,\n",
    "merge, publish, distribute, sublicense, and/or sell copies of the Software, and to\n",
    "permit persons to whom the Software is furnished to do so.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,\n",
    "INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n",
    "PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n",
    "HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    "OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n",
    "SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5f4a2cf",
   "metadata": {},
   "source": [
    "# Building Amazon Personalize Online Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89072a8c",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Python ships with a broad collection of libraries and we need to import those as well as the ones installed to help us like [boto3](https://aws.amazon.com/sdk-for-python/) (AWS SDK for python) and [Pandas](https://pandas.pydata.org/)/[Numpy](https://numpy.org/) which are core data science tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b66d59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from yaml import safe_load\n",
    "import requests\n",
    "import random \n",
    "from decimal import *\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9806d6",
   "metadata": {},
   "source": [
    "Next you will want to validate that your environment can communicate successfully with Amazon Personalize, the lines below do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc20de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "personalize_client = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24674bf",
   "metadata": {},
   "source": [
    "## Specify an S3 Bucket and Data Output Location\n",
    "\n",
    "Amazon Personalize will need an S3 bucket to act as the source of your data. The code bellow will create a bucket with a unique `bucket_name`.\n",
    "\n",
    "The Amazon S3 bucket needs to be in the same region as the Amazon Personalize resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e080fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sets the same region as current Amazon SageMaker Notebook\n",
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print('region:', region)\n",
    "\n",
    "# Or you can specify the region where your bucket and model will be domiciled\n",
    "# region = \"us-east-1\" \n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name =  \"personalize-demo-{}\".format(account_id) \n",
    "print('bucket_name:', bucket_name)\n",
    "\n",
    "try: \n",
    "    if region == \"us-east-1\":\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    else:\n",
    "        s3.create_bucket(\n",
    "            Bucket = bucket_name,\n",
    "            CreateBucketConfiguration={'LocationConstraint': region}\n",
    "            )\n",
    "except s3.exceptions.BucketAlreadyOwnedByYou:\n",
    "    print(\"Bucket already exists. Using bucket\", bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81958a",
   "metadata": {},
   "source": [
    "## Download, Prepare, and Upload Training Data\n",
    "\n",
    "First we need to download the data (training data). In this tutorial we'll use the Purchase history from a retail store  dataset. The dataset contains the user id,items id,the interaction between customers and items and the time this interaction took place(Timestamp) \n",
    "\n",
    "### Download and Explore and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a5a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !aws s3 cp s3://retail-demo-store-us-east-1/csvs/items.csv .\n",
    "!aws s3 cp s3://retail-demo-store-us-east-1/csvs/interactions.csv ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a206a2",
   "metadata": {},
   "source": [
    "The dataset has been successfully downloaded as Electronics_Store_purchase_history.csv\n",
    "\n",
    "Lets learn more about the dataset by viewing its charateristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35342317",
   "metadata": {},
   "source": [
    "### Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c7dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./interactions.csv')\n",
    "df.EVENT_TYPE.value_counts()\n",
    "def convert_event_type(event_type_in_some_format):\n",
    "    if(event_type_in_some_format == \"ProductViewed\"):\n",
    "        return \"View\"\n",
    "    if(event_type_in_some_format == \"OrderCompleted\"):\n",
    "        return \"Purchase\"\n",
    "    else:\n",
    "        return event_type_in_some_format\n",
    "\n",
    "df['EVENT_TYPE'] = df['EVENT_TYPE'].apply(convert_event_type)\n",
    "df.EVENT_TYPE.value_counts()\n",
    "\n",
    "test=df.drop(columns=['DISCOUNT'])\n",
    "df=test\n",
    "display(df.sample(5))\n",
    "df.to_csv(\"cleaned_training_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a90346",
   "metadata": {},
   "source": [
    "#### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a052f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get user ids from the interaction dataset\n",
    "user_ids = df['USER_ID'].unique()\n",
    "users_df = pd.DataFrame()\n",
    "users_df[\"USER_ID\"]=user_ids\n",
    "\n",
    "np.random.seed(123)\n",
    "possible_genders = ['female', 'male']\n",
    "random_ = np.random.choice(possible_genders, len(users_df.index), p=[0.5, 0.5])\n",
    "users_df[\"GENDER\"] = random_\n",
    "users_df.to_csv(\"users.csv\", index=False)\n",
    "\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ab5f53",
   "metadata": {},
   "source": [
    "#### Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b159ec75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def put_random_inventory(x):\n",
    "    sample_store_id = [\"store\"+str(x) for x in range(1,11)]\n",
    "    sample_num_stocks = 10 * np.array(list(range(1,11)))\n",
    "\n",
    "    store_inv_dict = {}\n",
    "    for i in range(5):\n",
    "        store_id_idx = random.randint(0,9)\n",
    "        num_stocks_idx = random.randint(0,9)\n",
    "\n",
    "        store_id_ = str(sample_store_id[store_id_idx])\n",
    "        num_stocks_ = sample_num_stocks[num_stocks_idx]\n",
    "        store_inv_dict[store_id_] = num_stocks_\n",
    "    return store_inv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed537c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items_url = 'https://raw.githubusercontent.com/aws-samples/retail-demo-store/master/src/products/src/products-service/data/products.yaml'\n",
    "raw_txt = requests.get(items_url).content\n",
    "\n",
    "items_df = pd.json_normalize(safe_load(raw_txt))\n",
    "\n",
    "drop_col_names = ['current_stock', 'image', 'gender_affinity', 'where_visible', 'featured', 'image_license', 'link', 'aliases']\n",
    "\n",
    "items_df = items_df.drop(labels= drop_col_names, axis=1)\n",
    "\n",
    "items_df = items_df.rename(columns={'id':'ITEM_ID', \n",
    "                                    'name':'NAME',\n",
    "                                    'category':'CATEGORY_L1',\n",
    "                                    'style':'CATEGORY_L2',\n",
    "                                    'description':'PRODUCT_DESCRIPTION',\n",
    "                                    'price':'PRICE',\n",
    "                                   })\n",
    "# items_df.columns = items_df.columns.str.upper()\n",
    "\n",
    "ts= datetime.datetime(2022, 1, 1, 0, 0).strftime('%s')\n",
    "ts = datetime.datetime.now().strftime('%s')\n",
    "items_df[\"CREATION_TIMESTAMP\"] = ts\n",
    "\n",
    "\n",
    "random_store_inv_df = items_df[['ITEM_ID']].applymap(put_random_inventory)\n",
    "items_df[['STORE_INVENTORY']]= random_store_inv_df\n",
    "\n",
    "\n",
    "items_df['STORE_IDS_AVAILABLE']= items_df['STORE_INVENTORY'].apply(lambda x: set(x.keys()))\n",
    "\n",
    "items_df.to_csv(\"items_with_store_inv.csv\", index=False)\n",
    "\n",
    "items_df['STORE_IDS_AVAILABLE'] =items_df['STORE_IDS_AVAILABLE'].apply(lambda x: \"|\".join(x))\n",
    "items_df = items_df.drop(labels=[\"STORE_INVENTORY\"], axis=1)\n",
    "items_df.to_csv(\"items.csv\", index=False)\n",
    "items_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a03250f",
   "metadata": {},
   "source": [
    "In the cells below, we will write our cleaned data to a file named \"final_training_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a725fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# move all the datasetGroup files in data folder\n",
    "!mkdir -p datasets\n",
    "!cp cleaned_training_data.csv ./datasets/cleaned_training_data.csv\n",
    "!cp users.csv ./datasets/users.csv\n",
    "!cp items.csv ./datasets/items.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d796882",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_file_name = 'cleaned_training_data.csv'\n",
    "s3_prefix = \"dataset/uploads/interaction\"\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(s3_prefix +\"/\"+interactions_file_name).upload_file(interactions_file_name)\n",
    "interactions_s3DataPath = \"s3://{}/{}/{}\".format(bucket_name, s3_prefix, interactions_file_name)\n",
    "print(interactions_s3DataPath)\n",
    "\n",
    "users_file_name = 'users.csv'\n",
    "s3_prefix = \"dataset/uploads/users\"\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(s3_prefix +\"/\"+users_file_name).upload_file(users_file_name)\n",
    "users_s3DataPath = \"s3://{}/{}/{}\".format(bucket_name, s3_prefix, users_file_name)\n",
    "print(users_s3DataPath)\n",
    "\n",
    "items_file_name = 'items.csv'\n",
    "s3_prefix = \"dataset/uploads/items\"\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(s3_prefix +\"/\"+items_file_name).upload_file(items_file_name)\n",
    "items_s3DataPath = \"s3://{}/{}/{}\".format(bucket_name, s3_prefix, items_file_name)\n",
    "print(items_s3DataPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee76ed30",
   "metadata": {},
   "source": [
    "## Configure an S3 bucket and an IAM role\n",
    "\n",
    "So far, we have downloaded, manipulated, and saved the data onto the Amazon EBS instance attached to instance running this Jupyter notebook. However, Amazon Personalize will need an S3 bucket to act as the source of your data, as well as IAM roles for accessing that bucket. Let's set all of that up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9559ee7",
   "metadata": {},
   "source": [
    "## Set the S3 bucket policy\n",
    "Amazon Personalize needs to be able to read the contents of your S3 bucket. So add a bucket policy which allows that.\n",
    "\n",
    "Note: Make sure the role you are using to run the code in this notebook has the necessary permissions to modify the S3 bucket policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:PutObject\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2b629",
   "metadata": {},
   "source": [
    "## Create and Wait for Dataset Group\n",
    "The largest grouping in Personalize is a Dataset Group, this will isolate your data, event trackers, solutions, Recommenders, and campaigns. Grouping things together that share a common collection of data. Feel free to alter the name below if you'd like.\n",
    "\n",
    "### Create Dataset Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f95598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = personalize_client.create_dataset_group(\n",
    "    name='personalize_demo_ecomemerce_dsg_v1',\n",
    "    domain='ECOMMERCE'\n",
    ")\n",
    "\n",
    "dataset_group_arn = response['datasetGroupArn']\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355ef591",
   "metadata": {},
   "source": [
    "Wait for Dataset Group to Have ACTIVE Status\n",
    "Before we can use the Dataset Group in any items below it must be active, execute the cell below and wait for it to show active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434cb727",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize_client.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec3c7b",
   "metadata": {},
   "source": [
    "## Create Interactions + User + Items Schema\n",
    "A core component of how Personalize understands your data comes from the Schema that is defined below. This configuration tells the service how to digest the data provided via your CSV file. Note the columns and types align to what was in the file you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"EVENT_TYPE\",\n",
    "            \"type\": \"string\"\n",
    "            \n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    interactions_schema_response = personalize_client.create_schema(\n",
    "        name = \"personalize-demo-ecommerce-interaction-schema-v1\",\n",
    "        domain = \"ECOMMERCE\",\n",
    "        schema = json.dumps(interactions_schema)\n",
    "    )\n",
    "\n",
    "    interactions_schema_arn = interactions_schema_response['schemaArn']\n",
    "    print(json.dumps(interactions_schema_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2affe59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Users\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "      {\n",
    "          \"name\": \"USER_ID\",\n",
    "          \"type\": \"string\"\n",
    "      },\n",
    "      {\n",
    "          \"name\": \"GENDER\",\n",
    "          \"type\": \"string\",\n",
    "          \"categorical\": True\n",
    "      }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    users_schema_response = personalize_client.create_schema(\n",
    "        name = \"personalize-demo-ecommerce-users-schema-v1\",\n",
    "        domain = \"ECOMMERCE\",\n",
    "        schema = json.dumps(users_schema)\n",
    "    )\n",
    "\n",
    "    users_schema_arn = users_schema_response['schemaArn']\n",
    "    print(json.dumps(users_schema_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2833775",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_schema = {\n",
    "   \"type\":\"record\",\n",
    "   \"name\":\"Items\",\n",
    "   \"namespace\":\"com.amazonaws.personalize.schema\",\n",
    "   \"fields\":[\n",
    "      {\n",
    "         \"name\":\"ITEM_ID\",\n",
    "         \"type\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"name\":\"STORE_IDS_AVAILABLE\",\n",
    "         \"type\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"name\":\"NAME\",\n",
    "         \"type\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"name\":\"CATEGORY_L1\",\n",
    "         \"type\":[\n",
    "            \"string\"\n",
    "         ],\n",
    "         \"categorical\":True\n",
    "      },\n",
    "      {\n",
    "         \"name\":\"CATEGORY_L2\",\n",
    "         \"type\":[\n",
    "            \"string\"\n",
    "         ],\n",
    "         \"categorical\":True\n",
    "      },\n",
    "      {\n",
    "         \"name\":\"PRODUCT_DESCRIPTION\",\n",
    "         \"type\": [\n",
    "            \"null\",\n",
    "            \"string\"\n",
    "          ],\n",
    "          \"textual\": True\n",
    "        },\n",
    "      {\n",
    "         \"name\":\"PRICE\",\n",
    "         \"type\":\"float\"\n",
    "      },\n",
    "      {\n",
    "         \"name\":\"CREATION_TIMESTAMP\",\n",
    "         \"type\":\"long\"\n",
    "      }\n",
    "   ],\n",
    "   \"version\":\"1.0\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    items_schema_response = personalize_client.create_schema(\n",
    "        name = \"personalize-demo-ecommerce-items-schema-v1\",\n",
    "        domain = \"ECOMMERCE\",\n",
    "        schema = json.dumps(items_schema)\n",
    "    )\n",
    "\n",
    "    items_schema_arn = items_schema_response['schemaArn']\n",
    "    print(json.dumps(items_schema_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0eb64f",
   "metadata": {},
   "source": [
    "## Create Datasets\n",
    "After the group, the next thing to create is the actual datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7754669",
   "metadata": {},
   "source": [
    "### Create Interactions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "try:\n",
    "    create_dataset_response = personalize_client.create_dataset(\n",
    "        name = \"personalize_demo_ecommerce_interactions_v1\",\n",
    "        datasetType = dataset_type,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        schemaArn = interactions_schema_arn\n",
    "    )\n",
    "\n",
    "    interactions_dataset_arn = create_dataset_response['datasetArn']\n",
    "    print(json.dumps(create_dataset_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdac4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"USERS\"\n",
    "try:\n",
    "    create_dataset_response = personalize_client.create_dataset(\n",
    "        name = \"personalize_demo_ecommerce_users_v1\",\n",
    "        datasetType = dataset_type,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        schemaArn = users_schema_arn\n",
    "    )\n",
    "\n",
    "    users_dataset_arn = create_dataset_response['datasetArn']\n",
    "    print(json.dumps(create_dataset_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4415e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"ITEMS\"\n",
    "try:\n",
    "    create_dataset_response = personalize_client.create_dataset(\n",
    "        name = \"personalize_demo_ecommerce_items_v1\",\n",
    "        datasetType = dataset_type,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        schemaArn = items_schema_arn\n",
    "    )\n",
    "\n",
    "    items_dataset_arn = create_dataset_response['datasetArn']\n",
    "    print(json.dumps(create_dataset_response, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c78dc8",
   "metadata": {},
   "source": [
    "## Create Personalize Role\n",
    "Also Amazon Personalize needs the ability to assume Roles in AWS in order to have the permissions to execute certain tasks, the lines below grant that.\n",
    "\n",
    "Note: Make sure the role you are using to run the code in this notebook has the necessary permissions to create a role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39925ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeDemoRoleEcommerceRecommender\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c64f46",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "Earlier you created the DatasetGroup and Dataset to house your information, now you will execute an import job that will load the data from S3 into Amazon Personalize for usage building your model.\n",
    "### Create Interactions + Users + Items Dataset Import Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_interactions_dataset_import_job_response = personalize_client.create_dataset_import_job(\n",
    "    jobName = \"personalize_demo_ecommerce_interactions_import_v1\",\n",
    "    datasetArn = interactions_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": interactions_s3DataPath\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_interactions_import_job_arn = create_interactions_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_interactions_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b98e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_users_dataset_import_job_response = personalize_client.create_dataset_import_job(\n",
    "    jobName = \"personalize_demo_ecommerce_users_import_v1\",\n",
    "    datasetArn = users_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": users_s3DataPath\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_users_import_job_arn = create_users_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_users_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_items_dataset_import_job_response = personalize_client.create_dataset_import_job(\n",
    "    jobName = \"personalize_demo_ecommerce_items_import_v1\",\n",
    "    datasetArn = items_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": items_s3DataPath\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_items_import_job_arn = create_items_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_items_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9150ad",
   "metadata": {},
   "source": [
    "Wait for Dataset Import Job to Have ACTIVE Status\n",
    "It can take a while before the import job completes, please wait until you see that it is active below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "    \n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize_client.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_interactions_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"Interactions DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize_client.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_users_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"Users DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "    \n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize_client.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_items_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"Items DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec7fb5",
   "metadata": {},
   "source": [
    "# Train and Deploy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_recipes = personalize_client.list_recipes(domain='ECOMMERCE') # See a list of recommenders for the domain. \n",
    "for recipe in available_recipes['recipes']:\n",
    "    print(recipe['recipeArn'])\n",
    "    \n",
    "print(\"***************************\")\n",
    "personalize_recipes = personalize_client.list_recipes()\n",
    "for recipe in personalize_recipes['recipes']:\n",
    "    print(recipe['recipeArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2598a8a7",
   "metadata": {},
   "source": [
    "We are going to create a recommender of the type \"Customers who frequently bought together items\". This recommender gives recommendations items that customers frequently buy together along with an item that you specify. With this use case, Amazon Personalize automatically finds similar items the user purchased based on the userId that you specify and `Purchase` events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3db4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequently_bought_together_recipe_arn = 'arn:aws:personalize:::recipe/aws-ecomm-frequently-bought-together'\n",
    "recommended_for_you_recipe_arn = 'arn:aws:personalize:::recipe/aws-ecomm-recommended-for-you'\n",
    "sims_recipe_arn= 'arn:aws:personalize:::recipe/aws-similar-items'\n",
    "rerank_recipe_arn = \"arn:aws:personalize:::recipe/aws-personalized-ranking\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f47d25",
   "metadata": {},
   "source": [
    "## 1: AWS Similar Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a622d",
   "metadata": {},
   "source": [
    "#### a) Create the solution\n",
    "\n",
    "As with the previous solution, start by creating the solution first. Although you provide the dataset ARN in this step, the model is not yet trained. See this as an identifier instead of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ad8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_solution_response = personalize_client.create_solution(\n",
    "    name = \"personalize-demo-sim-v1\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = sims_recipe_arn\n",
    ")\n",
    "\n",
    "sim_solution_arn = sim_solution_response['solutionArn']\n",
    "print(json.dumps(sim_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37d072",
   "metadata": {},
   "source": [
    "#### b) Create the solution version\n",
    "\n",
    "Once you have a solution, you need to create a version in order to complete the model training. The training can take a while to complete, upwards of 25 minutes, and an average of 35 minutes for this recipe with our dataset. Normally, we would use a while loop to poll until the task is completed. However the task would block other cells from executing, and the goal here is to create many models and deploy them quickly. So we will set up the while loop for all of the solutions further down in the notebook. There, you will also find instructions for viewing the progress in the AWS console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_solution_version_response = personalize_client.create_solution_version(\n",
    "    solutionArn = sim_solution_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_solution_version_arn = sim_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(sim_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c3db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_progress_solution_versions = [\n",
    "    sim_solution_version_arn\n",
    "]\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    for solution_version_arn in in_progress_solution_versions:\n",
    "        version_response = personalize_client.describe_solution_version(\n",
    "            solutionVersionArn = solution_version_arn\n",
    "        )\n",
    "        status = version_response[\"solutionVersion\"][\"status\"]\n",
    "        \n",
    "        if status == \"ACTIVE\":\n",
    "            print(\"Build succeeded for {}\".format(solution_version_arn))\n",
    "            in_progress_solution_versions.remove(solution_version_arn)\n",
    "        elif status == \"CREATE FAILED\":\n",
    "            print(\"Build failed for {}\".format(solution_version_arn))\n",
    "            in_progress_solution_versions.remove(solution_version_arn)\n",
    "    \n",
    "    if len(in_progress_solution_versions) <= 0:\n",
    "        break\n",
    "    else:\n",
    "        print(\"At least one solution build is still in progress\")\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4882ecf",
   "metadata": {},
   "source": [
    "## 2: Frequently Bought Together Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_recommender_response = personalize_client.create_recommender(\n",
    "  name = 'personalize-demo-frequently-bought-together-v1',\n",
    "  recipeArn = frequently_bought_together_recipe_arn,\n",
    "  datasetGroupArn = dataset_group_arn\n",
    ")\n",
    "frequently_bought_together_arn = create_recommender_response[\"recommenderArn\"]\n",
    "print (json.dumps(create_recommender_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 10*60*60 # 10 hours\n",
    "\n",
    "while time.time() < max_time:\n",
    "\n",
    "    version_response = personalize_client.describe_recommender(\n",
    "        recommenderArn = frequently_bought_together_arn\n",
    "    )\n",
    "    status = version_response[\"recommender\"][\"status\"]\n",
    "\n",
    "    if status == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(frequently_bought_together_arn))\n",
    "        \n",
    "    elif status == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(frequently_bought_together_arn))\n",
    "        \n",
    "\n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "    else:\n",
    "        print('The \"Customers who viewed X also viewed\" Recommender build is still in progress')\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c43f6",
   "metadata": {},
   "source": [
    "## 3: Personalized Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5baa3",
   "metadata": {},
   "source": [
    "### Personalized Ranking\n",
    "\n",
    "Personalized Ranking is an interesting application of HRNN. Instead of just recommending what is most probable for the user in question, this algorithm takes in a user and a list of items as well. The items are then rendered back in the order of most probable relevance for the user. The use case here is for filtering on genre for example, or when you have a broad collection that you would like better ordered for a particular user.\n",
    "\n",
    "For our use case, using the LastFM data, we could imagine that a particular record label is paying us to recommend their artists to our users in a special promotion. Therefore, we know the list of artists we want to recommend, but we want to find out which of these artists each user will like most. We would use personalized ranking to re-order the list of artists for each user, based on their previous tagging history. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57443e8e",
   "metadata": {},
   "source": [
    "#### a) Create the solution\n",
    "\n",
    "As with the previous solution, start by creating the solution first. Although you provide the dataset ARN in this step, the model is not yet trained. See this as an identifier instead of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3283c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_create_solution_response = personalize_client.create_solution(\n",
    "    name = \"personalize-demo-ranking-v1\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = rerank_recipe_arn\n",
    ")\n",
    "\n",
    "rerank_solution_arn = rerank_create_solution_response['solutionArn']\n",
    "print(json.dumps(rerank_create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d30d5",
   "metadata": {},
   "source": [
    "#### b) Create the solution version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb59992",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_create_solution_version_response = personalize_client.create_solution_version(\n",
    "    solutionArn = rerank_solution_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943cea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_solution_version_arn = rerank_create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(rerank_create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df2a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_progress_solution_versions = [\n",
    "    rerank_solution_version_arn\n",
    "]\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    for solution_version_arn in in_progress_solution_versions:\n",
    "        version_response = personalize_client.describe_solution_version(\n",
    "            solutionVersionArn = solution_version_arn\n",
    "        )\n",
    "        status = version_response[\"solutionVersion\"][\"status\"]\n",
    "        \n",
    "        if status == \"ACTIVE\":\n",
    "            print(\"Build succeeded for {}\".format(solution_version_arn))\n",
    "            in_progress_solution_versions.remove(solution_version_arn)\n",
    "        elif status == \"CREATE FAILED\":\n",
    "            print(\"Build failed for {}\".format(solution_version_arn))\n",
    "            in_progress_solution_versions.remove(solution_version_arn)\n",
    "    \n",
    "    if len(in_progress_solution_versions) <= 0:\n",
    "        break\n",
    "    else:\n",
    "        print(\"At least one solution build is still in progress\")\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac0534",
   "metadata": {},
   "source": [
    "#### c) Create campaigns <a class=\"anchor\" id=\"create\"></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "A campaign is a hosted solution version; an endpoint which you can query for recommendations. Pricing is set by estimating throughput capacity (requests from users for personalization per second). When deploying a campaign, you set a minimum throughput per second (TPS) value. This service, like many within AWS, will automatically scale based on demand, but if latency is critical, you may want to provision ahead for larger demand. For this POC and demo, all minimum throughput thresholds are set to 1. For more information, see the [pricing page](https://aws.amazon.com/personalize/pricing/).\n",
    "\n",
    "Let's start deploying the campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_create_campaign_response = personalize_client.create_campaign(\n",
    "    name = \"personalize-demo-campaign-rerank-v1\",\n",
    "    solutionVersionArn = rerank_solution_version_arn,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "\n",
    "rerank_campaign_arn = rerank_create_campaign_response['campaignArn']\n",
    "print(json.dumps(rerank_create_campaign_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f946cc",
   "metadata": {},
   "source": [
    "#### View campaign creation status\n",
    "\n",
    "As promised, how to view the status updates in the console:\n",
    "\n",
    "* In another browser tab you should already have the AWS Console up from opening this notebook instance. \n",
    "* Switch to that tab and search at the top for the service `Personalize`, then go to that service page. \n",
    "* Click `View dataset groups`.\n",
    "* Click the name of your dataset group, most likely something with POC in the name.\n",
    "* Click `Campaigns`.\n",
    "* You will now see a list of all of the campaigns you created above, including a column with the status of the campaign. Once it is `Active`, your campaign is ready to be queried.\n",
    "\n",
    "Or simply run the cell below to keep track of the campaign creation status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df7a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_progress_campaigns = [\n",
    "    rerank_campaign_arn\n",
    "]\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    for campaign_arn in in_progress_campaigns:\n",
    "        version_response = personalize_client.describe_campaign(\n",
    "            campaignArn = campaign_arn\n",
    "        )\n",
    "        status = version_response[\"campaign\"][\"status\"]\n",
    "        \n",
    "        if status == \"ACTIVE\":\n",
    "            print(\"Build succeeded for {}\".format(campaign_arn))\n",
    "            in_progress_campaigns.remove(campaign_arn)\n",
    "        elif status == \"CREATE FAILED\":\n",
    "            print(\"Build failed for {}\".format(campaign_arn))\n",
    "            in_progress_campaigns.remove(campaign_arn)\n",
    "    \n",
    "    if len(in_progress_campaigns) <= 0:\n",
    "        break\n",
    "    else:\n",
    "        print(\"At least one campaign build is still in progress\")\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622dff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b259ff15",
   "metadata": {},
   "source": [
    "## 4: Recommended For you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_recommender_response = personalize_client.create_recommender(\n",
    "  name = 'personalize-demo-recommended-for-you-v1',\n",
    "  recipeArn = recommended_for_you_recipe_arn,\n",
    "  datasetGroupArn = dataset_group_arn\n",
    ")\n",
    "recommended_for_you_arn = create_recommender_response[\"recommenderArn\"]\n",
    "print (json.dumps(create_recommender_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 10*60*60 # 10 hours\n",
    "\n",
    "while time.time() < max_time:\n",
    "\n",
    "    version_response = personalize_client.describe_recommender(\n",
    "        recommenderArn = recommended_for_you_arn\n",
    "    )\n",
    "    status = version_response[\"recommender\"][\"status\"]\n",
    "\n",
    "    if status == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(recommended_for_you_arn))\n",
    "        \n",
    "    elif status == \"CREATE FAILED\":\n",
    "        print(\"Build failed for {}\".format(recommended_for_you_arn))\n",
    "        \n",
    "\n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "    else:\n",
    "        print('The \"Customers who viewed X also viewed\" Recommender build is still in progress')\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9a249",
   "metadata": {},
   "source": [
    "# Create Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43185e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = personalize_client.create_filter(\n",
    "    name = 'available_items_filter',\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    filterExpression = 'INCLUDE ItemID WHERE Items.STORE_IDS_AVAILABLE IN ($STORE_ID)'\n",
    "    # filterExpression = 'INCLUDE ItemID WHERE Items.CATEGORY_L1 = $category_l1'\n",
    ") \n",
    "filter_arn = response[\"filterArn\"]\n",
    "print(\"Filter ARN: \" + filter_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232721b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 10*60*60 # 10 hours\n",
    "\n",
    "while time.time() < max_time:\n",
    "\n",
    "    version_response = personalize_client.describe_filter(filterArn= filter_arn)\n",
    "    status = version_response[\"filter\"][\"status\"]\n",
    "\n",
    "    if status == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(filter_arn))\n",
    "        \n",
    "    elif status == \"CREATE FAILED\":\n",
    "        print(\"F failed for {}\".format(filter_arn))\n",
    "        \n",
    "\n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "    else:\n",
    "        print('The \"available_items_filter\" Filter build is still in progress')\n",
    "        \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585881bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id = \"777\"\n",
    "\n",
    "# Select a random item\n",
    "test_item_id = \"8fbe091c-f73c-4727-8fe7-d27eabd17bea\" # a random item: 8fbe091c-f73c-4727-8fe7-d27eabd17bea\n",
    "\n",
    "# Get recommendations for the user for this item\n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    recommenderArn = frequently_bought_together_arn,\n",
    "    itemId = test_item_id,\n",
    "    userId = test_user_id, \n",
    "    \n",
    "    numResults = 10,\n",
    "    promotions = [{\n",
    "            \"name\" : \"Seasonal-Items-Promotion\",\n",
    "            \"percentPromotedItems\" : 50,\n",
    "            \"filterArn\": filter_arn,\n",
    "            \"filterValues\": {\n",
    "               \"STORE_ID\": json.dumps(\"store1\")\n",
    "            } \n",
    "          }]\n",
    ")\n",
    "\n",
    "# Build a new dataframe for the recommendations\n",
    "item_list = get_recommendations_response['itemList']\n",
    "\n",
    "for item in item_list:\n",
    "    if (\"promotionName\" in item):\n",
    "        print(item['itemId'] , \"   \", item['promotionName'])\n",
    "    else:\n",
    "        print (item['itemId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"777\"\n",
    "rerank_item_list = ['0790267c-c708-424d-81f5-46903a9c8444','575c0ac0-5494-4c64-a886-a9c0cf8b779a','4cf78f85-4200-469c-b7b9-05c93770bf44','b20ba076-58a7-4602-9b56-4bee46e98388','aff05423-76e8-4339-a478-fc17d51ed985','a6432520-a9fe-42a3-8e04-58cd50d18fb0','4a43c5f7-090c-4cce-93fe-36062539ec38','f1e0660b-53db-4e9a-a86a-8a990d6b2988']\n",
    "\n",
    "get_recommendations_response_rerank = personalize_runtime.get_personalized_ranking(\n",
    "        campaignArn = rerank_campaign_arn,\n",
    "        userId = user_id,\n",
    "        inputList = rerank_item_list,\n",
    "        filterArn = filter_arn,\n",
    "        filterValues = {\n",
    "                \"STORE_ID\": json.dumps(\"store1\")\n",
    "            } \n",
    "    # promotions = [{\n",
    "    #         \"name\" : \"Seasonal-Items-Promotion\",\n",
    "    #         \"percentPromotedItems\" : 50,\n",
    "    #         \"filterArn\": filter_arn,\n",
    "    #         \"filterValues\": {\n",
    "    #           \"category_l1\": json.dumps(\"seasonal\")\n",
    "    #         } \n",
    "    #       }]\n",
    ")\n",
    "\n",
    "get_recommendations_response_rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pick a user\n",
    "user_id = \"777\"\n",
    "\n",
    "print(filter_arn)\n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    recommenderArn = recommended_for_you_arn,\n",
    "    userId = user_id,\n",
    "    numResults = 10,\n",
    "     promotions = [{\n",
    "            \"name\" : \"Seasonal-Items-Promotion\",\n",
    "            \"percentPromotedItems\" : 50,\n",
    "            \"filterArn\": filter_arn,\n",
    "            \"filterValues\": {\n",
    "              \"STORE_ID\": json.dumps(\"store1\")\n",
    "            } \n",
    "          }]\n",
    ")\n",
    "\n",
    "print(json.dumps(get_recommendations_response['itemList'], indent=2))\n",
    "\n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    recommenderArn = recommended_for_you_arn,\n",
    "    userId = user_id,\n",
    "    numResults = 10,\n",
    "    filterArn = filter_arn,\n",
    "    filterValues = {\n",
    "              \"STORE_ID\": json.dumps(\"store1\")\n",
    "            } \n",
    ")\n",
    "\n",
    "print(json.dumps(get_recommendations_response['itemList'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7363c83-0761-454c-8430-008905c2fd6f",
   "metadata": {},
   "source": [
    "## Notes for the Next Notebook:\n",
    "\n",
    "There are a few values you will need for the next notebook, execute the cells below to store them so they can be copied and pasted into the next part of the exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d38a70-6eea-4fac-990f-437e9db581bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store dataset_group_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822f565-a9ee-4486-950d-3a7f1bcf1195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03298465-2a60-4992-ba09-a18435626fee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store role_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34631fe1",
   "metadata": {},
   "source": [
    "# Getting recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b5da0",
   "metadata": {},
   "source": [
    "### a) AWS Similar Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a064072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the original data in order to have a dataframe that has both item_ids \n",
    "# and the corresponding titles to make out recommendations easier to read.\n",
    "items_df = pd.read_csv('./items.csv')\n",
    "\n",
    "num_of_items = items_df.shape[0]\n",
    "\n",
    "\n",
    "item_list = items_df.sample(num_of_items)['ITEM_ID'].tolist()\n",
    "print(len(item_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240abbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_input_filename = \"items.jsonl\"\n",
    "with open(json_input_filename, 'w') as json_input:\n",
    "    for item in item_list:\n",
    "        json_input.write('{\"itemId\": \"' + item + '\"}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix_batch = \"dataset/uploads/items\"\n",
    "s3_ip_val = \"{}/{}\".format(s3_prefix_batch, json_input_filename)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(s3_ip_val).upload_file(json_input_filename)\n",
    "s3_input_path = \"s3://\" + bucket_name + \"/\"+ s3_ip_val\n",
    "print(s3_input_path)\n",
    "\n",
    "s3_op_val = \"batched_output\"\n",
    "s3_output_path = \"s3://\" + bucket_name + \"/\" + s3_op_val + \"/\"\n",
    "print(s3_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d5515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batchInferenceJobResponse = personalize_client.create_batch_inference_job (\n",
    "    solutionVersionArn = sim_solution_version_arn,\n",
    "    jobName = \"sim-itesm-batch-inference-0\",\n",
    "    roleArn = role_arn,\n",
    "    jobInput = \n",
    "       {\"s3DataSource\": {\"path\": s3_input_path}},\n",
    "    jobOutput = \n",
    "       {\"s3DataDestination\": {\"path\": s3_output_path}}\n",
    ")\n",
    "\n",
    "batchInferenceJobArn = batchInferenceJobResponse['batchInferenceJobArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa0d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "current_time = datetime.now()\n",
    "print(\"Import Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_inference_job_response = personalize_client.describe_batch_inference_job(\n",
    "        batchInferenceJobArn = batchInferenceJobArn\n",
    "    )\n",
    "    status = describe_dataset_inference_job_response[\"batchInferenceJob\"]['status']\n",
    "    print(\"DatasetInferenceJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.now()\n",
    "print(\"Import Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf06682b",
   "metadata": {},
   "source": [
    "### b) Frequently Bought Together \n",
    "Now that the recommenders have been trained, lets have a look at the recommendations we can get for our users!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_by_id(item_id, item_df):\n",
    "    \"\"\"\n",
    "    This takes in an item_id from a recommendation in string format,\n",
    "    converts it to an int, and then does a lookup in a default or specified\n",
    "    dataframe and returns the item description.\n",
    "    \n",
    "    A really broad try/except clause was added in case anything goes wrong.\n",
    "    \n",
    "    Feel free to add more debugging or filtering here to improve results if\n",
    "    you hit an error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return items_df.loc[items_df[\"ITEM_ID\"]==str(item_id)]['PRODUCT_DESCRIPTION'].values[0]\n",
    "    except:\n",
    "        print (item_id)\n",
    "        return \"Error obtaining item description\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9828551",
   "metadata": {},
   "source": [
    "Let us get some recommendations using the \"Customers who viewed X also viewed\" Recommender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f7fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pick a user\n",
    "test_user_id = \"777\"\n",
    "\n",
    "# Select a random item\n",
    "test_item_id = \"8fbe091c-f73c-4727-8fe7-d27eabd17bea\" # a random item: 8fbe091c-f73c-4727-8fe7-d27eabd17bea\n",
    "\n",
    "# Get recommendations for the user for this item\n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    recommenderArn = frequently_bought_together_arn,\n",
    "    itemId = test_item_id,\n",
    "    userId = test_user_id,\n",
    "    numResults = 10\n",
    ")\n",
    "\n",
    "# Build a new dataframe for the recommendations\n",
    "item_list = get_recommendations_response['itemList']\n",
    "recommendation_list = []\n",
    "\n",
    "for item in item_list:\n",
    "    item = get_item_by_id(item['itemId'], items_df)\n",
    "    recommendation_list.append(item)\n",
    "\n",
    "user_recommendations_df = pd.DataFrame(recommendation_list, columns = [get_item_by_id(test_item_id, items_df)])\n",
    "\n",
    "pd.options.display.max_rows =10\n",
    "display(user_recommendations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b69455",
   "metadata": {},
   "source": [
    "### c) Personalized Ranking\n",
    "The core use case for personalized ranking is to take a collection of items and to render them in priority or probable order of interest for a user. To demonstrate this, we will need a random user and a random collection of 25 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5244618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"interactions.csv\")\n",
    "rerank_user = df.sample(1).index.tolist()[0]\n",
    "rerank_items = items_df.sample(10)['ITEM_ID'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e41244",
   "metadata": {},
   "source": [
    "Now build a nice dataframe that shows the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_list = []\n",
    "for item in rerank_items:\n",
    "    prod_desc = get_item_by_id(item, items_df)\n",
    "    rerank_list.append(prod_desc)\n",
    "rerank_df = pd.DataFrame(rerank_list, columns = [rerank_user])\n",
    "rerank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31e6d3",
   "metadata": {},
   "source": [
    "Then make the personalized ranking API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b383922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user to string:\n",
    "user_id = str(rerank_user)\n",
    "rerank_item_list = []\n",
    "for item in rerank_items:\n",
    "    rerank_item_list.append(str(item))\n",
    "    \n",
    "# Get recommended reranking\n",
    "get_recommendations_response_rerank = personalize_runtime.get_personalized_ranking(\n",
    "        campaignArn = rerank_campaign_arn,\n",
    "        userId = user_id,\n",
    "        inputList = rerank_item_list\n",
    ")\n",
    "\n",
    "get_recommendations_response_rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e18d2",
   "metadata": {},
   "source": [
    "Now add the reranked items as a second column to the original dataframe, for a side-by-side comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_list = []\n",
    "item_list = get_recommendations_response_rerank['personalizedRanking']\n",
    "for item in item_list:\n",
    "    prod_desc = get_item_by_id(item['itemId'], items_df)\n",
    "    ranked_list.append(prod_desc)\n",
    "ranked_df = pd.DataFrame(ranked_list, columns = ['Re-Ranked'])\n",
    "rerank_df = pd.concat([rerank_df, ranked_df], axis=1)\n",
    "rerank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91236034",
   "metadata": {},
   "source": [
    "You can see above how each entry was re-ordered based on the model's understanding of the user. This is a popular task when you have a collection of items to surface a user, a list of promotions for example, or if you are filtering on a category and want to show the most likely good items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a312f57",
   "metadata": {},
   "source": [
    "### d) Recommended For you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01efa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pick a user\n",
    "user_id = \"777\"\n",
    "\n",
    "\n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    recommenderArn = recommended_for_you_arn,\n",
    "    userId = user_id,\n",
    "    numResults = 10\n",
    ")\n",
    "get_recommendations_response['itemList']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cf8367",
   "metadata": {},
   "source": [
    "## Put Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b67a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import time\n",
    "\n",
    "personalize_events= boto3.client(service_name='personalize-events')\n",
    "\n",
    "user_id = '4353'\n",
    "item_id = '6579c22f-be2b-444c-a52b-0116dd82df6c'\n",
    "session_id = str(uuid.uuid1())\n",
    "\n",
    "def create_event_tracker(event_tracker_name, dataset_group_arn):\n",
    "    response = personalize_client.create_event_tracker(\n",
    "                name= event_tracker_name,\n",
    "                datasetGroupArn= dataset_group_arn\n",
    "            )\n",
    "    return response\n",
    "\n",
    "\n",
    "def send_movie_click(user_id, item_id, session_id, event_tracking_id):\n",
    "    event = {\n",
    "            \"itemId\": str(item_id),\n",
    "            }\n",
    "    event_json = json.dumps(event)\n",
    "        \n",
    "    # Make Call\n",
    "    response = personalize_events.put_events(\n",
    "            trackingId = event_tracking_id,\n",
    "            userId= user_id,\n",
    "            sessionId = session_id,\n",
    "            eventList = [{\n",
    "                'sentAt': int(time.time()),\n",
    "                'eventType': 'View',\n",
    "                'properties': event_json\n",
    "                }]\n",
    "        )\n",
    "    return response\n",
    "\n",
    "event_tracker_name = 'websiteClickEvent'\n",
    "res = create_event_tracker(event_tracker_name, dataset_group_arn)\n",
    "\n",
    "event_tracker_arn = res['eventTrackerArn']\n",
    "tracking_id = res['trackingId']\n",
    "\n",
    "print(res['eventTrackerArn'])\n",
    "print(res['trackingId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86541c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_time = time.time() + 10*60*60 # 10 hours\n",
    "\n",
    "while time.time() < max_time:\n",
    "\n",
    "    version_response = personalize_client.describe_event_tracker(eventTrackerArn= event_tracker_arn)\n",
    "    status = version_response[\"eventTracker\"][\"status\"]\n",
    "\n",
    "    if status == \"ACTIVE\":\n",
    "        print(\"Build succeeded for {}\".format(filter_arn))\n",
    "        \n",
    "    elif status == \"CREATE FAILED\":\n",
    "        print(\"F failed for {}\".format(filter_arn))\n",
    "        \n",
    "\n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "    else:\n",
    "        print('The \"websiteClickEvent\" Filter build is still in progress')\n",
    "        \n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "send_movie_click(user_id, item_id, user_id, res['trackingId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68665c1a",
   "metadata": {},
   "source": [
    "## Review\n",
    "Using the codes above you have successfully trained a deep learning model to generate item recommendations based on prior user behavior. You have created two recommenders for two foundational use cases. \n",
    "Going forward, you can adapt this code to create other recommenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b07561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "624104a4",
   "metadata": {},
   "source": [
    "## Only Run Below cells after the deploying the CDK stack!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42f62e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CDK attribute : SimilarItemsInput\n",
    "sim_items_input_bucket_name =  # sim_items_input_bucket_name = 're-similaritemsinputa49dd15f-15butx9ehcxmk'\n",
    "\n",
    "# CDK attribute : ItemsTable \n",
    "items_table_name =  # items_table_name = 'RE-ItemsTable5AAC2C46-U483L1G6EUB8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f258423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the table created by the CDK \"ItemsTable\" attribute  \n",
    "df = pd.read_csv(\"./datasets/items_with_store_inv.csv\")\n",
    "df = df.rename(columns={ 'ITEM_ID':'id',\n",
    "                         'NAME':'name',\n",
    "                         'CATEGORY_L1':'categoryL1',\n",
    "                         'CATEGORY_L2':'categoryL2',\n",
    "                         'PRODUCT_DESCRIPTION':'productDescription',\n",
    "                         'PRICE':'price',\n",
    "                         'CREATION_TIMESTAMP':'creationTimestamp',\n",
    "                         'STORE_INVENTORY':'storeInventory',\n",
    "                         'STORE_IDS_AVAILABLE':'storeIdsAvailable'\n",
    "                       }\n",
    "              )\n",
    "\n",
    "total_items = len(df)\n",
    "table = dynamodb_resource.Table(items_table_name)\n",
    "tic = time.time()\n",
    "try:\n",
    "    with table.batch_writer() as batch:\n",
    "        for index, row in df.iterrows():\n",
    "            a = json.loads(row.to_json(), parse_float=Decimal)\n",
    "            a[\"storeInventory\"] = ast.literal_eval(a[\"storeInventory\"])\n",
    "            a[\"storeIdsAvailable\"] = ast.literal_eval(a[\"storeIdsAvailable\"])\n",
    "            batch.put_item(Item = a)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "toc = time.time()\n",
    "exec_time = round((toc-tic), 2)\n",
    "response = \"time took to put {} items in dynamoDb is {} seconds\".format(total_items, exec_time)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d987a0",
   "metadata": {},
   "source": [
    "### Upload to S3\n",
    "Now that our training data is ready for Amazon Personalize,the next step is to upload it to the s3 bucket created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17f92d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interactions_file_name = 'cleaned_training_data.csv'\n",
    "s3_prefix = \"dataset/uploads/interaction\"\n",
    "boto3.Session().resource('s3').Bucket(sim_items_input_bucket_name).Object(s3_prefix +\"/\"+interactions_file_name).upload_file(interactions_file_name)\n",
    "interactions_s3DataPath = \"s3://{}/{}/{}\".format(sim_items_input_bucket_name, s3_prefix, interactions_file_name)\n",
    "print(interactions_s3DataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba2aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_file_name = 'users.csv'\n",
    "s3_prefix = \"dataset/uploads/users\"\n",
    "boto3.Session().resource('s3').Bucket(sim_items_input_bucket_name).Object(s3_prefix +\"/\"+users_file_name).upload_file(users_file_name)\n",
    "users_s3DataPath = \"s3://{}/{}/{}\".format(sim_items_input_bucket_name, s3_prefix, users_file_name)\n",
    "print(users_s3DataPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b07234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items_file_name = 'items.csv'\n",
    "s3_prefix = \"dataset/uploads/items\"\n",
    "boto3.Session().resource('s3').Bucket(sim_items_input_bucket_name).Object(s3_prefix +\"/\"+items_file_name).upload_file(items_file_name)\n",
    "items_s3DataPath = \"s3://{}/{}/{}\".format(sim_items_input_bucket_name, s3_prefix, items_file_name)\n",
    "print(items_s3DataPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283c06f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_input_filename = 'items.jsonl'\n",
    "s3_client.upload_file(json_input_filename, sim_items_input_bucket_name, json_input_filename)\n",
    "s3_items_jsonl_path = \"s3://\" + bucket_name + \"/\"+ json_input_filename\n",
    "print(s3_items_jsonl_path)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "personalize-online-recommendations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bff1259f98d32ffcf3925dd8a7d9d1c21bb80233c335e9a28e5f469731584841"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
